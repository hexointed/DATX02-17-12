Sphere Tracing:
	
	(QS 1)
	Vårt projekts mål har varit att utreda en alternativ grafikrenderingsmetod 
	som kallas Sphere Tracing, och utifrån detta, designa en grafikprocessor 
	optimerad för denna. Detta ville vi göra eftersom man kan se att prestandan 
	för metoden, när den körs på en konventionell GPU, blir kraftigt begränsad. 
	
	(QS 2)
	Detta kommer sig av att en grafikprocessor gjord för polygonrendering gör 
	antaganden om att dess många kärnor gruppvis alltid arbetar med samma 
	instruktion. Detta tillåter många kärnor att dela på instruktionsminne 
	vilket gör det möjligt att få plats med fler kärnor på samma chip. Då 
	Sphere Tracing arbetar med skiljda loop-längder per stråle, så kan den på 
	en konventionell GPU inte uppnå sin fulla potential.
	
	(QS 3)
	Så varför just Sphere Tracing?  För att motivera vårt intresse börjar vi 
	med att kort beskriva hur metoden fungerar, samt några sätt att förbättra 
	algoritmen, som vi kom fram till under projektets utredningsfas.
	
	Vad är då Sphere Tracing?
	
	(- How Sphere Tracing works.)
	
	Sphere Tracing är en variant av sk Ray Tracing, vilket är en 
	grafikrenderingsmetod baserad på att projicera strålar, från en kamera, 
	mot en uppsättning av 3D-Objekt. Det objekt som strålen träffar först 
	avgör vilken färg den korresponderande pixeln på skärmen kommer att få. 
	Detta kräver mycket datorkraft då man ofta måste lösa 
	differentialekvationer för att hitta skärningspunkterna mellan strålen  
	och objekten. Sphere Tracing är ett alternativ till att hitta denna 
	skärningspunkt, vilket görs genom att först definiera alla objekt som 
	sk distansfunktioner. Dessa är funktioner som tar en given 3d-koordinat 
	och returnerar avståndet till den punkt på funktionsytan som ligger 
	närmast in-koordinaten. Detta möjliggör en effektiv ray-marching längs 
	strålen, vilket ger högre prestanda än konventionell Ray Tracing. 
	(bilderbilder...)
				
	 - optimizations
		Describe each
		Show with/without optimizations to show fps difference
		visa visuellt, demonstrera hastighetsförbättring?

		- Orthogonal Culling
			Orthogonal Culling används för att minska antalet distans-fält 
			uträkningar som behöver göras per steg genom att räkna ut vilka
			objekt i scenen som strålen kan träffa. Varje stråle följer en 
			linje, genom att ortogonalt projicera objekts centrum på linjen
			kan man räkna ut om de ligger framför strålen eller inte. Om 
			objektet inte ligger framför strålen så slutar man räkna ut 
			avståndet till det, för det kan inte träffas ändå.

		- Bounding Sphere
			Bounding Spheres används för att minska antalet uträkningar som 
			behöver göras innan strålen är i närheten av objekt som den kanske
			kommer träffa. Flera objekt placeras inuti en större sfär, 
			istället för att räkna ut avståndet till alla objekt så används
			bara sfären. Om en stråle träffar en Bounding Sphere så tas den bort
			och alla objekt inuti används igen. 



	- Software shader	
		berätta att dessa optimeringar är implementerade och testade i en sk 
		shader, ett program som körs på en GPU i en vanlig speldator. 
		(ge visuellt exempel med flowchart)		

	- Vad är då Sphere Tracing bra för?
		Denna algoritm fungerar väldigt annorlunda än polygonrendering, och blir
		därför intressant då den kan vara väldigt snabb på många
		grafikrenderingsmetoder som traditionella polygonrenderare har svårt
		för. Exempel på detta visas här i vår shader, som visar hur ytan på en
		sfär kan se mjuk ut, oavsett zoom-nivå. I polygonmodellen syns skarpa
		kanter vid inzoomning, och skulle man öka antalet polygoner för att
		klara kraftig inzoomning så skulle prestandan istället sänkas alltför
		mycket. (visa inzoomning av 2 sfärer närbild), 
		mjuk geometri-blending mellan objekt (kan visas med metabollarna), äkta
		reflektion/refraktion (visa nån fin interreflektion, t.ex i
		metabollarna), 
		[permuterbar geometrirepetition]
			Även repetition av objekt i alla dimensioner går att göra med en 
			fast hastighetskostnad, till skillnad från det klassiska fallet som 
			har en linjärt ökande kostnad för antal utritade objekt. Varje 
			repeterat objekt kan skilja sig från sina grannar då dess utseende 
			kan varieras och animeras med hjälp av t.ex dess position eller id. 
			Detta medför att stora fält av intressant geometri kan renderas 
			extremt snabbt.	(visa animerat våg-sfär-fält),

		Ytterligare saker: penumbra-skuggning (inigos bilder?),	
		tredimensionella material,  (kanske bara skriva dessa i text på slides)

Processor:
	
	- Architecture overview
	- Assembler

	Utöver detta har vi också byggt en GPU, eftersom ett av målen med projektet
	var att designa hårdvara som är gjord för Sphere Tracing. GPU:n som vi 
	designade blev också en mer generell parallellprocessor, eftersom vi tyckte
	att det ökade möjligheterna för att enkelt kunna implementera de 
	optimeringar som vi diskuterade tidigare på processorn.

	För arkitekturen i sig beslutade vi att lägga mindre fokus på lockstepping
	än traditionella grafikkort, då alla rays kan variera kraftigt i antal
	steg, vilka objekt som är nära, samt när de är klara. Kärnorna i vår GPU
	har alltså lite mer kontrolllogik per beräkningsenhet än traditionella
	grafikkort, men mindre, och därmed fler, kärnor än en CPU. Tillsammans med
	kärnorna behövs ett sätt att representera alla de strålar som behöver
	beräknas. 

	Vi ville också, om möjligt, kunna skapa nya strålar on demand för att
	enkelt kunna implementera t.ex. reflektioner och refraktioner, som är
	relativt enkla att göra med raymarching, och som vore tråkiga att gå miste
	om. Vi valde därför att designa GPU:n så att alla shaders som kör på den
	kör i en slags trådar, och att varje tråd får möjligheten att skapa nya
	trådar. Sedan lade vi till en kö som alla kärnor kunde kommunicera med, där
	kärnorna kan lägga upp nya trådar, och hämta trådar för att börja exekvera.

	[Bild Arkitektur]

	Detta visade sig vara en ganska användbar arkitektur som det utan större
	problem går att implementera allt som krävs för att kunna köra Sphere 
	Tracing, men möjligtvis även för andra typer av problem som både är mycket
	parallella men även iterativa/rekursiva och har lite mer komplicerade 
	programflöden, vilket lätt skapar problem när de körs på locksteppade 
	arkitekturer.

	[Bild Assembler]

	Vi behövde också kunna programmera GPU:n enkelt, och därför designade vi
	ett assemblerspråk åt den. Det ser ut som de flesta assemblerspråk, men är
	lite intressant på grund av hårdvarustödet för trådar. Trådstödet gör
	faktiskt assemblern lite mer ovanlig en enbart att det finns instruktioner
	som hanterar trådar, det gjorde även att vi kunde låta bli att implementera
	jump-instruktioner, eftersom de kan ersättas genom att skapa en kopia av
	den nuvarande tråden med en instruktionspekare som pekar dit man vill
	hoppa, följt av att man terminerar den nuvarande tråden. Det låter dyrare 
	än det behöver vara, 

Square Roots:
	
	- Fast approximation
	- Improved approximation
	- Lerp/Babylonian
	- Shifting nth root
	- Sphere Tracing fault tolerance
	
	För att kunna räkna ut längder till alla objekten i scenen behövdes roten
	ur användas.  Vi insåg ganska snabbt att det det var en väldigt krävande
	operation, och om vi kunde optimera implementationen av roten ur skulle det
	potentiellt kunna spara både tid och area i GPU:n

	*Bild fast approx

	Vi hittade en snabb men grov approximering  som bara använde sig utav en
	rad or-gatear.  Den utnyttjar det faktum att antalet bitar halveras vid
	roten ur, och ger e En bättre approximering är denna:

	*Bild improved approx

	Denna implementationen har fler or-gatear och deras placeringar är baserat
	på bit mönstret för roten ur 2.

	lerp/babylonian?

	shifting?
	
	Vi jobbade även med Dijkstras square root algorithm som beräknar roten ur
	på en bit åt gången. Denna algorithm var ursprungligen inte så bra för en
	högpresterande hårdvaruimplementering eftersom addition och subtraktion var
	för kostsamma. Men efter optimeringarna som vi gjorde (help) lyckades vi
	minska kostanden för addition och subraktion.

	Hur hög fel tolerans har då sphere tracing? Hur exakt måste roten ur vara
	för sphere tracen skall fungera?  Det beror på olika saker, vi har det
	satta epsilonet, sträckan som avgjorde om vi var "tillräckligt" nära för
	att säga att vi träffat. Om vi har ett större fel än vårt epsilon riskerar
	vi att overstepa och poteniellt missa objekt.  Ett annat kritiskt tillfälle
	där fel tolerans är viktigt är när vi räknar ut normalen som vi använder
	för att räkna ut reflektioner och skuggor. Får vi fel värde värde på
	normalen riskerar vi att stega i fel riktning och då reflektera fel saker
	eller få en missvisande skuggning.

Conclusion:
	
	- More work needed on GPU for more meaningful conclusions
	- Sphere Tracing has interesting properties

	Sphere tracing har definitivt fördelar och nackdelar kontra polygon baserad
	rendering, och det finns fortfarande mycket som kan göra sphere tracing
	bättre och snabbare. Vi har testat två optimeringar på algoritmen och visat
	att dem ökar prestandan. Men vi tror att det finns mycket mer kvar att
	lära. 

	Vi anser att det behövs läggas mer tid på alla delar i projektet för att
	kunna gör en realistisk bedömning av potentialen i en GPU  byggd för Sphere
	Tracing algoritmen. Det vi har lärt oss under vårat utförande av projektet
	är hur många delar med Sphere tracing som ännu är outforskade.	
