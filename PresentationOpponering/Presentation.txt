Sphere Tracing:
	
	(QS 1)
	Vårt projekts mål har varit att utreda en alternativ grafikrenderingsmetod 
	som kallas Sphere Tracing, och utifrån detta, designa en grafikprocessor 
	optimerad för denna. Detta ville vi göra eftersom man kan se att prestandan 
	för metoden, när den körs på en konventionell GPU, blir kraftigt begränsad. 
	
	(QS 2)
	Detta kommer sig av att en grafikprocessor gjord för polygonrendering gör 
	antaganden om att dess många kärnor gruppvis alltid arbetar med samma 
	instruktion.(peka på en grupp) Detta kallas lockstepping och tillåter att 
	många kärnor
	delar instruktionsminne, vilket gör det möjligt att få plats med fler 
	kärnor på 
	ett och samma chip. Då Sphere Tracing arbetar med skilda loop-längder per 
	stråle, 
	så kan den på en konventionell GPU inte uppnå sin fulla potential.
	
	(QS 3)
	/*Så varför just Sphere Tracing?  För att motivera vårt intresse börjar vi 
	med att kort beskriva hur metoden fungerar, samt några sätt att förbättra 
	algoritmen, som vi kom fram till under projektets utredningsfas.*/
	
	Vad är då Sphere Tracing?	
	Sphere Tracing är en variant av sk Ray Tracing, vilket är en 
	grafikrenderingsmetod baserad på att projicera strålar, från en kamera, 
	mot en uppsättning av 3D-Objekt. 

	(QS 4)
	Det objekt som strålen träffar först avgör vilken färg den motsvarande 
	pixeln på skärmen kommer att få. 
	Detta kräver mycket datorkraft då man ofta måste lösa 
	differentialekvationer för att hitta skärningspunkterna mellan strålen och 
	objekten. 

	(QS 5)
	Sphere Tracing är ett alternativ till att hitta denna 
	skärningspunkt, vilket görs genom att först definiera alla objekt som 
	sk distansfunktioner. Dessa är funktioner som tar en given 3d-koordinat 
	och returnerar avståndet till den punkt på objektet som ligger 
	närmast input-koordinaten. De blåa punkterna är alltså input-koordinater 
	och längden på 
	den röda linjen är det minsta avståndet till objektets yta.

	(QS 6)
	Detta gör att man kan hitta skärningspunkter genom 
	att successivt stega sig längs med strålen, där varje steglängd avgörs av 
	nuvarande avstånd till närmsta objekt. 

	(QS 7 - animation-bildserien som visar en stråle marschera genom terräng)
	Trots att algoritmen alltså måste ta flera steg för att nå fram till en 
	skärningspunkt, så är den beräkningsmässiga kostnaden totalt ändå mycket 
	lägre än vid klassisk Ray Tracing.
					
	För att ytterligare öka metodens prestanda så har vi skapat och 
	implementerat två olika optimeringar.

	- Ortogonal Culling	
		(QS 8 - Bild utan orthogonal culling)	
		Ortogonal Culling används för att minska antalet distansuträkningar som 
		behöver göras per steg genom att räkna ut vilka	objekt i scenen som 
		strålen aldrig kommer att träffa. Genom att ortogonalt projicera ett 
		objekts centrumpunkt på strålen så kan man avgöra om objektet skär dess 
		väg. 
	
		(QS 9 - bild med orthogonal culling)		
		Detta görs för alla objekt vid strålens början, vilket medför att varje 
		påföljande steg längs med denna kan skippa onödiga distansberäkningar.	
	
	- Bounding Sphere
		(QS 10 - bild med bounding sphere)
		Bounding Spheres används för att minska antalet uträkningar som 
		behöver göras innan strålen är i närheten av objekt som den kanske
		kommer träffa. Flera objekt placeras inuti en större sfär, och
		istället för att räkna ut avståndet till alla objekt så evalueras 
		endast denna sfärs distansfunktion. Detta ger väldigt enkla beräkningar 
		för varje steg fram tills att strålen skär den omslutande sfären. Först 
		därefter behöver samtliga inneslutna objekts avstånd beräknas.
	
	- Software shader
		(QS 11 - flowchart )
		Optimeringarna är implementerade och testade i sk shaders, dvs program
		som körs på en grafikprocessor. Den är implementerad dels i 
		shader-språket GLSL och dels i vårt eget assembler-språk.
		Det här flödesschemat beskriver 
		grovt vår implementation av algoritmen. 
		
		/* Anledningen till att Bounding 
		Spheres tekniken inte syns i flödesschemat är att det behandlas som ett
		vanligt objekt.*/

	- Vad är då Sphere Tracing bra för?
		Denna algoritm fungerar väldigt annorlunda från polygonrendering, och blir
		därför intressant då den kan vara väldigt snabb på många
		grafikrenderingsmetoder som traditionella polygonrenderare har svårt
		för. 
			(QS 12 - startframe i film för poly-vs-dist)
			
		Ett exempel på detta visas här i vår GLSL-shader, som visar hur ytan på vår
		sfär kan se mjuk ut, oavsett zoom-nivå. 
		
			(inzoomning av 2 sfärer närbild, tala vidare direkt)
			
		Medans i polygonmodellen syns skarpa
		kanter vid inzoomning, och skulle man öka antalet polygoner för att
		klara kraftig inzoomning så skulle prestandan istället sänkas alltför
		mycket. 
		
		
			(QS 13 - Bild på 2 statiska reflektiva metabollar, första frame i 
			anim)
			
		även mjuk sammansmältning av objekt kan göras genom att vikta ihop 
		distansfunktionerna för två olika objekt.
		
			(Spela animationen till mitten)
		
		Äkta reflektioner och refraktioner är enkla att beräkna genom att beräkna 
		reflektionsvektorn och starta om "loopen" vid reflektionspunkten.
		Här ser vi en stråle speglas flera gånger fram och tillbaka i sfärerna innan den 
		slutligen studsar ut i omgivningsbilden.
		
		(Spela animationen till sitt slut)
		
		[permuterbar geometrirepetition]
		
			Även repetition av objekt i alla dimensioner går att göra med en 
			fast hastighetskostnad, till skillnad från det klassiska fallet som 
			har en linjärt ökande kostnad för antal utritade objekt. Varje 
			repeterat objekt kan skilja sig från sina grannar då dess utseende 
			kan varieras och animeras med hjälp av t.ex dess position eller id. 
			Detta medför att stora fält av intressant geometri kan renderas 
			extremt snabbt.	

			(visa animerat våg-sfär-fält),

		Ytterligare saker: penumbra-skuggning (inigos bilder?),	
		tredimensionella material,  (kanske bara skriva dessa i text på slides)

Processor:
	(QS 14)
	Vi har även byggt en GPU, eftersom ett av målen med projektet
	var att designa hårdvara som är gjord för Sphere Tracing. GPU:n som vi 
	designade blev mer utav en generell parallellprocessor, än vi först tänkt 
	oss.  
	Anledingen till det, var att vi bedömde att det ökade möjligheterna för att 
	enkelt kunna implementera de optimeringar som tidigare nämnts.

	- Architecture overview
	För arkitekturen i sig beslutade vi att lägga mindre fokus på lockstepping
	än traditionella grafikkort, då alla rays kan variera kraftigt i antal
	steg, vilka objekt som är nära, samt när de är klara. Kärnorna i vår GPU
	har alltså lite mer kontrolllogik per beräkningsenhet än traditionella
	grafikkort, men mindre, och därmed fler kärnor än en CPU. Tillsammans med
	kärnorna behövs ett sätt att representera alla de strålar som behöver
	beräknas. 

	(QS 15 Bild Arkitektur)
	Vi ville också, om möjligt, kunna skapa nya strålar on demand för att
	enkelt kunna implementera t.ex. reflektioner och refraktioner, som är
	relativt enkla att göra med raymarching, och som vore tråkiga att gå miste
	om. Vi valde därför att designa GPU:n så att alla shaders som kör på den
	kör i en slags trådar, och att varje tråd får möjligheten att skapa nya
	trådar. Sedan lade vi till en kö som alla kärnor kunde kommunicera med, där
	kärnorna kan lägga upp nya trådar, och hämta trådar för att börja exekvera.


	Detta visade sig vara en ganska användbar arkitektur som det utan större
	problem går att implementera allt som krävs för att kunna köra Sphere 
	Tracing, men möjligtvis även för andra typer av problem som både är mycket
	parallella men även iterativa/rekursiva och har lite mer komplicerade 
	programflöden, vilket lätt skapar problem när de körs på locksteppade 
	arkitekturer.

	- Assembler
	[Bild Assembler]
	Vi behövde också kunna programmera GPU:n enkelt, och därför designade vi
	ett assemblerspråk åt den. Det liknar de flesta assemblerspråken, men är
	lite intressant tack vare hårdvarustödet för trådar. Trådstödet gör
	faktiskt assemblern lite mer ovanlig en enbart att det finns instruktioner
	som hanterar trådar, det gjorde även att vi kunde låta bli att implementera
	jump-instruktioner, eftersom de kan ersättas genom att skapa en kopia av
	den nuvarande tråden med en instruktionspekare som pekar dit man vill
	hoppa, följt av att man terminerar den nuvarande tråden. Det låter dyrare
	än det behöver vara, i vȧr GPU kräver ett hopp ungefär tre extra
	klockcykler pȧ grund av att trȧden först mȧste skickas till den globala
	trȧdlagringen och sedan tillbaka, men det är ocksȧ möjligt att ge varje
	kärna möjligheten att känna igen kombinationen pushq drop, eller lägga till
	en synonym instruktion till denna kombination och dȧ inte behöver skicka
	iväg trȧden frȧn kärnan.
	

Square Roots:
	
	- Fast approximation
	- Improved approximation
	- Lerp/Babylonian
	- Shifting nth root
	- Sphere Tracing fault tolerance

	En central del av Sphere Tracing är att räkna ut avstȧnd, sȧ att ta 
	kvadratrötter är en operation som är viktig. Kvadratrötter implementeras 
	ofta genom att man använder ett lookup-table för en ursprunglig gissning,
	följt av nȧgra steg av en iterativ algoritm sȧsom Goldschmidt's eller den
	babylonska metoden. Vi tittade pȧ lite andra metoder, bȧde för att göra den
	ursprungliga gissningen snabbt, samt för att räkna ut kvadratrötter exakt.

	Om vi börjar med lite approximationer. [Okej sȧ här va] Om man tar
	logaritmen av ett tal fȧr man ungefär hur mȧnga siffror talet innehȧller. 
	Att ta kvadratroten av ett tal är samma som att höja upp talet i 1/2. Och
	om vi tar logaritmen av ett tal upphöjt till 1/2 följer det av 
	logaritmlagarna att det blir lika med hälften av logaritmen av talet. Altsȧ
	har kvadratroten av ett tal ungefär hälften sȧ mȧnga siffror som det 
	ursprungliga talet. Baserat pȧ det tänkte vi oss först nȧgon typ av 
	bit-shift för att lösa problemet, men baserat pȧ hur stort talet är skulle
	det behöva shiftas olika mycket, sȧ vi kom istället fram till denna 
	lösning:

	[Bild fast approx]

	Denna ger dock en dȧlig approximation för udda tvȧpotenser, sȧ vi kan 
	förbättra den genom att tända lite extra lȧga bitar för de udda 
	inputbitarna. Detta ger en bättre approximation generellt, med ett maximalt 
	reletivt fel pȧ ungefär 30%

	[Bild improved approx]

	Vi testade ocksȧ att kombinera de här gissningarna bȧde med linjär 
	interpolation mellan tvȧpotenser och med den babylonska metoden, vilket
	gav ganska bra accuracy.

	[Bild lerp/babylonian]

	Vi jobbade även med Dijkstras square root algorithm som beräknar roten ur
	på en bit åt gången. Denna algorithm var ursprungligen inte så bra för en
	högpresterande hårdvaruimplementering eftersom addition och subtraktion var
	för kostsamma. Men efter optimeringarna som vi gjorde lyckades vi minska
	kostanden för addition och subraktion.

	Hur hög feltolerans har då sphere tracing? Hur exakt måste kvadratroten
	vara för att sphere tracern skall fungera?  Det beror på olika saker, vi har
	det satta epsilonet, sträckan som avgjorde om vi var "tillräckligt" nära
	för att säga att vi träffat. Om vi har ett större fel än vårt epsilon
	riskerar vi att overstepa och poteniellt missa objekt.  Ett annat kritiskt
	tillfälle där feltolerans är viktigt är när vi räknar ut normalen på ytan
	som vi använder för att räkna ut reflektioner och skuggor. Får vi fel värde
	värde på normalen riskerar vi att stega i fel riktning och då reflektera
	fel saker eller få en missvisande skuggning.

	Däremot fortsätter Sphere Tracing - algoritmen fungera korrekt även om man 
	underskattar kvadratrötterna när man bestämmer stegavstȧndet, och eftersom
	det relativa felet är begränsat är det möjligt med dessa metoder att aldrig
	överskatta det faktiska värdet för kvadratrötterna, och altsȧ möjligt att
	använda dem tillsammans med Sphere Tracing. Tyvärr försämras prestandan 
	nȧgot om avstȧnden underskattas för grovt pȧ grund av att man kan behöva ta
	fler steg innan avstȧndet till geometrin är tillräckligt litet. De allra 
	enklaste approximeringarna kommer altsȧ troligtvis inte, även om de är 
	intressanta, att vara särskilt användbara för Sphere Tracing pȧ egen hand,
	utan istället kombinerade med andra metoder för att förbättra precicionen.

Conclusion:

	- More work needed on GPU for more meaningful conclusions
	- Sphere Tracing has interesting properties

	Sphere tracing har definitivt fördelar och nackdelar kontra polygonbaserad
	rendering som xxx förklarade tidigare, och det finns fortfarande mycket som
	kan göra sphere tracing bättre och snabbare.  Vi har testat två
	optimeringar på algoritmen och visat att de ökar prestandan. Vi tror att
	vi kan öka prestandan ännu mer om man låter CPUn göra delar av
	uträkningarna istället för GPUn.  Vi tror att det finns mycket mer kvar
	att lära. 

	Vi anser att det behövs läggas mer tid på alla delar i projektet för att
	kunna gör en välgrundad bedömning av potentialen i en GPU  byggd för Sphere
	Tracing algoritmen. Det vi har lärt oss under vårat utförande av projektet
	är hur många delar med Sphere tracing som ännu är outforskade.	


Indelning av presentationen	

Introduktion:	Slide 1-2
	Jon, 1
Teori: 			Slide 3-7
	André, 1.5

Optimeringar:	Slide 8-11
	Jon, 1.5

Demonstration:	Slide 12-13
    André, 2.5

Hȧrdvara:		Slide 14
	Processorarkitektur-intro (QS 15): Chi, 1min
	Arkitektur+assembler: 	Elias, 3min

Sqrt:
	Elias - 5 min
	2 sista paragraferna: Jon, 1.75

Conclusion:
	Chi, 1
        
        
Jon: 1+1.5+1.75 = 4.25
André: 1.5+2.5	= 4
Chi: 1+1		= 2
Elias: 3+5		= 8


total tid
4.25+4+2+8
