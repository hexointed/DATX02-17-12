\chapter{Discussion} 

	This chapter will discuss our thoughts on our result, our theoretical not 
	yet	implemented optimizations, and what future work is possible from this 
	point in time.
	
	\section{Results}  \label{discussion}
		
		\subsection{Software Shader}
		
			The implemented optimizations improved performance more than
			anticipated.  This shows that there is more performance to be found
			in a conventional GPU than a straight-forward implementation of the
			algorithm. 

			There are great limitations in what could be done with the shader
			because of the language that we chose to implement it in, GLSL. It
			offers nothing more than a way to write a program which will be run
			on a per-pixel basis and put it on the screen. Because of this,
			CPU-GPU cooperation is completely impossible and that comes with
			consequences.

			Modern graphics engines not only do a lot of work on the CPU but it
			has granular control over the GPU, whereas we have no control at
			all. Things such as object positioning, frustum culling, etc.
			should be done by the CPU, not the GPU. This kind of implementation
			can not be done in GLSL and therefore a high-performance sphere
			tracer should be done not in GLSL but in a lower-level language.

			Although for our purposes, to build a sphere tracer where we
			quickly could implement optimizations, develop new features, study
			the algorithm, GLSL was a perfect fit. 

		
		\subsection{GPU} 
		
			The project originally intended to create a simple single-core GPU
			that could fully render a scene given enough time, and then add on
			components as time allowed. As happens with projects like these,
			every design decision one makes clarifies what further needs to be
			done and reveals previously unseen flaws in the design that needs
			to be resolved. In the end we implemented the core and enabled
			multiple cores running in parallel utilizing a storage manager. 
			
			If we were to continue the work in a future project we would
			rewrite the basic core in a number of ways, pushing it out to an FPGA to verify our design choices and try to be more empiric before
			extending further with more modules and ideas. 

	\section{Optimizations} \label{optimization}

		\subsection{Bounding spheres}
			
			Although an increase in performance could be seen using this
			method, it can also be used in ways that decreases the performance.
			By setting up a too large bounding sphere or my setting it up with
			few objects or simply objects that are far apart.

			To use this optimization efficiently the objects inside a bounding 
			sphere should never come far apart and the sphere should be exactly 
			the right size.

		\subsection{Orthogonal culling}

			The performance gain from this optimization exceeded our 
			expectations. This could probably be further improved by using
			another way to create the sphere tracer than GLSL. 

			However great the performance gain the way this is implemented
			is still far from the optimal solution, currently it performs 
			orthogonal culling on all the objects in the scene per pixel. 
			Instead, culling should be done on a per-object basis and calculate
			which rays an object intersects, this way fewer calculations would
			have to be performed and optimally they would be performed on the
			CPU.

			This method could work together with the Bounding Sphere 
			optimization. Instead of projecting single objects onto the ray,
			bounding spheres could be projected, decreasing the number of 
			orthogonal projections that has to be made. This too was tested 
			and an increase in performance was observed.

		\subsection{Square roots}

			as it is a common operation for Sphere Tracers that also
		

	\section{Future work}

		\subsection{GPU-CPU cooperation}
			One thing that could be done to improve performance is to let the
			processor handle object related math, such as object and camera 
			transformation. Currently if objects in the scene are supposed to 
			move without doing it manually, they have to be moved using 
			mathematical functions. These functions are then evaluated for 
			each march step, for each pixel, this is essentially wasted 
			computing power.


		\subsection{Plane-ray intersection}

			Infinite planes currently require a lot of computing power to
			render. When the camera is oriented so that the field of view is
			along an infinite plane some rays will travel parallel to the
			plane, these rays will march equally long steps until their max
			number of steps has been taken or the max range has been reached,
			without hitting anything. Another drawback of infinite planes is
			that the sphere tracing algorithm causes the horizon of planes to
			disappear because of the max range and max steps of a ray. Another
			way to render infinite planes might be to calculate if the ray will
			intersect the plane, and if so where it will intersect. This would
			eliminate the issue of not being able to render the horizon and
			might also increase performance.

			One potential problem is that because no distance field evaluations 
			are performed, it might be hard to perform Boolean operations or 
			mathematical deformations on planes rendered this way. Another is 
			that every time we add more features that aren't part of the regular 
			Sphere Tracing, the complexity of the program increases. Thus, the 
			advantages of the individual optimizations must be weighed against 
			the overall performance loss they incur. 

		\subsection{Overstepping}

			Bounding spheres technique is somewhat similar to the normal sphere
			tracing. The difference is that when you march you march to the
			edge of the MDS and then you march to the next MDS edge. With
			overstepping technique you march a small distance further
			outside the MDS edge. You then compare the original MDS with the
			new MDS if these two spheres overlap in any way we can march that
			little bit further. By marching that little bit further, decrease
			in the number of times marched is achieved. Giving an increase in
			performance. 
			
		\subsection{Ray grouping}
		
			Ray grouping works by grouping adjacent rays together.  If a specific
			pixel N is to be rendered we group the adjacent pixels into a set, then
			march along the ray of N. If any of the pixels are not inside the minimum
			distance spheres (MDS) the combined pixel is split up into smaller sets,
			which each have a centered pixel. Each set then repeats the these steps
			over and over again individually along their new center pixel's ray.
			This is repeated a number of times depending on the march distance in the
			scene for every set. The closer the sets are to a target, the more likely
			it is for a higher amount of subsets to be created due to the decrease of
			the MDS's volumes making less pixels fit inside.
			
			We believe ray grouping gives a performance increase by lowering the
			number of steps needed to march. Depending on the scene it could lower
			the steps significantly. One example would be a scene with only one
			object in it let's say a sphere, this implies that the MDS's volume will
			be substantial. This will in turn make the number of subgroups very low
			and give us a a performance gain. 
			
			A very complex scene with many objects creates very varying MDS volumes
			which would not give as good of a result as the earlier mentioned example
			due to the increase in subsets early in the marching.
			
