\chapter{Discussion}
	
	\section{Method}
		
		\subsection{\clash}

			For this project \clash was chosen as hardware description language.
			\clash is based on the functional programming language Haskell, and
			is relatively new and not yet fully stable. It differs from 
			traditional hardware description languages in that 

			One thing that \clash offers that proved to be very useful is the 
			avalability of a command-line repl. This improved testing and 
			debugging possibilities significantly, and was very useful in order
			to be able to quickly write and test new modules.

		\subsection{Hardware design}

			Many design decisions during the development of the gpu were not
			thoroughly researched or performance tested against possible
			alternatives. It is clear that doing so would have been desirable,
			both in order to improve performance of the resulting design and to
			get a better understanding of the possible design space. 
			Unfortunately, proper performance evaluation for all design 
			decisions would be very time consuming, and there was not enough 
			time for this during this project.

	\section{Results}
		
		\subsection{Software Shader}
		
			One thing that could be done to improve performance is to let the
			processor handle object related math, such as object and camera 
			transformation. Currently if objects in the scene are supposed to 
			move without doing it manually, they have to be moved using 
			mathematical functions. These functions are then evaluated for 
			each march step, for each pixel, this is essentially wasted 
			computing power.

			The method used to remove objects from the distance field should
			not be used the way it is currently used, although the current way
			certainly improves performance. Currently each ray calculates the
			distance to each object to decide whether it will collide or not. 
			This is a bad implementation because each ray calculates the 
			distance to each object. Instead this should be calculated on a 
			per-object basis, calculating which pixels each object will have
			a chance of covering. However, we did not have the time nor
			knowledge to implement this way, but the current implementation
			certainly enhances performance.



		
		\subsection{GPU} 
		
			The project originally intended to create a simple single-core GPU
			that could fully render a scene given enough time, and then add on
			components as time allowed. As happens with projects like these,
			every design decision one makes clarifies what further needs to be
			done and reveals previously unseen flaws in the design that needs
			to be resolved. In the end we implemented the core and enabled
			multiple cores running in parallel utilizing a global queue, with
			some caveats. While the implementation works and can be simulated
			for up to 128 cores we have only serialized 4 cores. 
			
			If we were to continue the work in a future project we would
			rewrite the basic core in a number of ways, pushing it out to FPGA
			to verify our design choices and try to be more empiric before
			extending further with more modules and ideas. 

	\section{Optimizations}

		\subsection{Bounding spheres}
	
			Bounding spheres technique is somewhat similar to the normal sphere
			tracing. The difference is that when you march you march to the
			edge of the MDS and then you march to the next MDS edge. With
			bounding sphere technique you march a small distance further
			outside the MDS edge. You then compare the original MDS with the
			new MDS if these two spheres overlap in any way we can march that
			little bit further. By marching that little bit further, decrease
			in the number of times marched is achieved. Giving an increase in
			performance. 
			
		
			%picture of example bounding sphere

		\subsection{Ray grouping}
		
			Ray grouping is an optimization that lowers the number of
			computations the GPU have to perform. And by lowering the number of
			computations it increases the speed of the GPU.
			
			It works like the name implicates by grouping adjacent rays
			together. If a specific pixel N is to be rendered we group the
			adjacent pixels into a ``combined pixel``. Then we march along the
			ray of N. If any of the other pixels are not inside the minimum
			distance spheres (MDS) the combined pixel is split up into two
			smaller groups. Each of the groups then repeat the first step again
			individually along their new center pixel's ray. This is repeated a
			number of times depending on the scene.  The closer to a target it
			gets, more subgroups will be created due to the MDS's volumes will
			decrease.
			
			This optimization was implemented and we achieved an increase in
			performance as excepted. The optimization decreases the number of
			computations made by the formula ? below.  Sum of $\sum_1^s(1/N_s)$
			where N = number of pixels in the group and s = number of groups

			%#picture of ray grouping

		\subsection{Orthogonal culling}

			Traditionally culling is done to avoid the GPU rendering polygons 
			that are outside the field of view, this is called frustum culling. Instead 
			of this we implemented an alternative version that we call orthogonal
			culling.

			Normally the closest distance to all objects in the scene is calculated
			in each march-step, for each pixel. One way to make this go faster is 
			reducing the number of objects that the distance has to be calculated 
			to, without reducing scene complexity. 

			To calculate whether the ray will hit a sphere or not orthogonal 
			projection can be used. By projecting the center of the sphere onto
			the directional line of the ray, its closest point to the line is known.
			Then the distance between the line and the sphere can be calculated using
			the radius, if the distance is less than zero the sphere will be hit
			by the ray. If the distance is larger than zero the ray can't possibly hit 
			that sphere. This way the number of objects that the distance has to be 
			calculated to is decreased. 

			This method could be combined with the Bounding Sphere optimization.
			By othogonally culling away bounding spheres instead of objects, 
			several objects could be discarded at once, reducing the computing
			time to calculate which objects the ray might hit.

	\section{Future work}

		\subsection{Software shader}

			\subsection{Plane-ray intersection}

				Infinite planes currently require a lot of computing power to render. When
				the camera is oriented so that the field of view is along an infinite
				plane some rays will travel parallell to the plane, these rays will march 
				equally long steps until their max number of steps has been taken or
				the max range has been reached, without hitting anything. Another
				drawback of infinite planes is that the sphere tracing algorithm causes
				the horizon of planes to disappear because of the max range and max 
				steps of a ray. Another way to render infinite planes might be to 
				calculate if the ray will intersect the plane, and if so where it 
				will intersect. This would eliminate the issue of not being able 
				to render the horizon and might also increase performance.

				One potential problem is that because no distance field evaluations 
				are performed, it might be hard to perform operations such as CSG or
				mathematical deformations on planes rendered this way.


		
			
