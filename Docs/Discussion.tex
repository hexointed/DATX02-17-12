\chapter{Discussion} 

	This chapter will discuss our thoughts on our result, our theoretical not
	yet	implemented optimizations, and what future work is possible from this
	point in time.
	
	\section{Development Environment}
		
		In this section we describe some project specific tools and our experience using them.
		
		\subsection{\clash}
			As described in \ref{FHDLs}, the ability to simulate the function of
			the GPU directly in a REPL was completely essential in us being able
			to complete a working GPU in the short time span available. The way
			\clash{} handles state is quite elegant and effective once one has
			learned the general pattern. Lists however, are too abstract for
			synthesis so \clash{}  uses its own vector type instead. Most 
			regular
			data functions are implemented, but all such vectors must have a
			fixed size. This makes some operations such as combining two vectors
			rather cumbersome and one has to work around this.
	
		\subsection{Synthclipse}
			This is an IDE for developing shaders, using GLSL or JSX. It has
			features for rapid recompilation and testing, easy resource loading 
			and	Uniform Controls. The Uniform Controls are a collection of user
			interface elements such as sliders and color pickers, which can be
			saved into Presets. These allowed us to navigate our scene and 
			modify its parameters on the fly, enabling visual examination and 
			debugging of our algorithms.		
		
		\section{Software Shader}

			The implemented optimizations increased the performance of our 
			shader and there are more improvements to implement. The potential
			of Sphere Tracing on conventional GPUs is hard to estimate but 
			it is certainly possible to develop our implementation further.
			
			GLSL has some very attractive features, it was easy to learn 
			because the syntax has much in common with C++. The time it takes 
			to develop new features and	test them is short. The purpose of the 
			software shader was to study the algorithm, implement and test 
			optimizations and develop new features. For the purposes of this 
			project GLSL was a perfect fit.
		
		\section{GPU} 
		
			The project originally intended to create a simple single-core GPU
			that could fully render a scene given enough time, and then add	
			components as time allowed. Every design decision one makes 
			clarifies what further needs to be done, and reveals previously 
			unseen flaws in the design that must
			be resolved. In the end we implemented the core and a storage 
			manager which enabled multiple cores running in parallel.

			The storage manager turned out to need to be more complex than we 
			originally anticipated. In its first implementation, the storage in
			the storage manager was a simple FIFO queue. This worked well for 
			very simple shader programs, but we found that it was not possible
			to write a full Sphere Tracer using this storage type. This was not
			due to any complexity inherent in the sphere tracing algorithm, but
			rather a consequence of how the GPU requires the shader programs to
			keep track of all pixels they need to render. This is solved by 
			having the shader generate a new thread for every pixel it needs to
			render, and then running the actual pixel shader code on that 
			thread. This fails when threads need to execute many jumps or 
			loops, which are also solved by spawning new threads. Whenever a 
			thread executed a jump, the pixel spawning thread took priority 
			because of the FIFO storage, and a new pixel thread would be 
			spawned. After many jumps, the storage in the storage manager would 
			fill up entirely, and all cores would stall waiting for the 
			storage manager allowing them to send it more threads. This was 
			solved by changing the internal storage to a double-ended queue,
			giving the threads some control over execution priority.

			If we were to continue working on this project another workflow
			would be adopted when developing the GPU. More detailed planning is
			required in the early stages and empiric testing of different
			implementations is required along the entire development to reach
			the best possible solution.

	\section{Optimizations} \label{optimization}

		\subsection{Bounding spheres}

			If used the right way this technique can give great performance 
			boosts. The testing showed an increase in gain as the number of 
			objects increased, which is promising.

			The test was in this case simpler than the issue. The results depend
			on more factors than we can analyze, the test only handles the 
			number of objects inside a fixed sphere. To be used in a optimal way
			the objects should be bound in a way similar to the one described in
			the subsection implementation\ref{implshader} but more adaptive, 
			enclosing objects depending how they are grouped per frame. 

		\subsection{Orthogonal culling}

			The performance gain from this optimization exceeded our 
			expectations. However great the performance gain, this
			is still far from the optimal implementation. It currently performs 
			Orthogonal Culling on all the objects in the scene, per pixel. 
			Instead, culling should be done once per object and calculate 
			which rays an object intersects, this way fewer calculations would
			have to be performed and optimally they would be performed on the
			CPU.

			This method could work together with the Bounding Sphere
			optimization. Instead of projecting single objects onto the ray,
			bounding spheres could be culled, decreasing the number of
			orthogonal projections that has to be made. This too was tested and
			an increase in performance was observed.

	\section{Square roots}

		The simple square root approximator and its improved version are
		extremely simple circuits, in fact they are significantly smaller than
		most other common operations performed on numbers in hardware. Of
		course, they are far from accurate, but we find it interesting that it
		is possible to achieve a bounded relative error from the true square
		root for any number of input bits with these small circuits. When
		combined with linear interpolation or iterative methods like the
		Babylonian method the accuracy of these approximations increases
		significantly.
		
		The shifting nth root algorithm is the only bit-accurate method tested,
		and it performs well, albeit slower than the approximations. If
		non-exact results are acceptable, which they often are to some extent
		when doing sphere tracing, the number of steps in the shifting nth root
		algorithm could be reduced, which would both increase speed and
		decrease area usage. The lerp-based and iterative methods might still
		be able to reuse common components such as adders and multipliers
		however, and might therefore be preferable.
		
		For the GPU, we have used the shifting nth root algorithm in order
		to not have to consider possible accuracy problems when debugging
		shaders, but all methods are implemented and ready to be switched out
		at any time.

	\section{Future work} \label{futureoptimizations} 

		\subsection{GPU-CPU cooperation}

			In the current implementation everything is performed on the GPU,
			including object transformations and culling. Currently if objects
			in the scene are supposed to move they have to be moved using
			mathematical functions, such as sinus. These functions are then
			evaluated for each march step. This is essentially wasted computing
			power and could be performed on the CPU as is standard in modern
			graphics engines.

		\subsection{Plane-ray intersection}

			Infinite planes currently require a lot of computing power to
			render. When the camera is oriented so that the field of view is
			along an infinite plane some rays will travel parallel to the
			plane. These rays will march equally long steps until their max
			number of steps has been taken or the max range has been reached, 
			without hitting anything. This will cause some rays to draw 
			computing power without ever being able to hit the plane anyway. 
			Some rays that should hit the plane will fail to do so because of 
			to many steps taken, making it look like the plane has an edge 
			because after a certain range it is no longer being rendered.

			One potential problem is that because no distance field evaluations 
			are performed, it might be hard to perform Boolean operations or 
			mathematical deformations on planes rendered this way. Another is 
			that every time we add more features that aren't part of the 
			regular Sphere Tracing, the complexity of the program increases. 
			Thus, the advantages of the individual optimizations must be 
			weighed against the overall performance loss they incur. 

		\subsection{Overstepping}

			Bounding spheres technique is somewhat similar to the normal sphere
			tracing. The difference is that when you march you march to the edge of
			the MDS and then you march to the next MDS edge. With overstepping
			technique you march a small distance further outside the MDS edge. You
			then compare the original MDS with the new MDS if these two spheres
			overlap in any way we can march that little bit further. By marching that
			little bit further, decrease in the number of times marched is achieved,
			giving an increase in performance. This has previously been discussed
			by\cite{Korndorfer2014}. 

		\subsection{Ray grouping}
		
			Ray grouping works by grouping adjacent rays together. If a
			specific pixel N is to be rendered we group the adjacent pixels
			into a set, then march along the ray of N. If any of the pixels are
			not inside the minimum distance spheres (MDS) the combined pixel is
			split up into smaller sets, which each have a centered pixel. Each
			set then repeats the these steps over and over again individually
			along their new center pixel's ray. This is repeated a number of
			times depending on the march distance in the scene for every set.
			The closer the sets are to a target, the more likely it is for a
			higher amount of subsets to be created due to the decrease of the
			MDS's volumes making less pixels fit inside.
			
			We believe ray grouping gives a performance increase by lowering
			the number of steps needed to march. Depending on the scene it
			could lower the steps significantly. One example would be a scene
			with only one object in it let's say a sphere, this implies that
			the MDS's volume will be substantial. This will in turn make the
			number of subgroups very low and give us a a performance gain. 
			
			A very complex scene with many objects creates very varying MDS
			volumes which would not give as good of a result as the earlier
			mentioned example due to the increase in subsets early in the
			marching.

	\section{Future impact on industry} 

		The GPU is still too underdeveloped to definitively show if the
		algorithm has potential one way or another.  Further prototypes needs
		to be built with greater rigor before that can happen. If we however
		assume that somewhere down the line it turns out to be a success,
		then there are generally three ways we can see that happening.
		
		First up is by breaking through in the games industry. Granted that
		it probably will not be able to outperform modern graphic cards at
		their own game even after improving the card as much as possible. But
		the up-and-coming VR technology faces different challenges, usually
		rendering smaller scenes with fewer objects and capturing actual
		``3D’’ images to display to the user. Both of these factors favors
		Sphere Tracing since it inherently produces perfect 3D objects and
		works much faster in scenes with shorter render distance.
		
		Another possibility is that the GPU turns out to be too slow for
		rendering games in real time, but runs other Ray Tracing algorithms
		commonly used in movie production faster that modern graphic cards.
		This is not too unlikely since the calculation of the rays in both
		cases follow many similar patterns in bouncing and reflecting etc.
		Movies are computed in render farms, where lots of
		copies of the same hardware works in tandem. This means that even a
		small improvement over current graphic cards might be amplified to a
		significant gain in computational power.
		?? ?? gäller la vanliga kort med?
		
		Finally, we designed our GPU similar to a CPU but with more	cores
		like a GPU except with no lockstepping. If this proves to be feasible
		for a full ASIC (Application-specific integrated circuit), then this
		type of processing unit would be better at parallel processing than a
		regular CPU, and it would perform better than a regular GPU at
		recursive and conditionally branching algorithms. This lends itself
		well to computations such as fractals, population simulation and
		artificial intelligence. It might also fit classes of computation not
		yet thought of, such in the example of Folding@Home\cite{Beberg2009}.
		They created software, deployed all over the world, to run on
		Graphics cards in home computers, when the computer was idle. So
		instead of wasting precious computing power, these GPUs, adept at
		parallel computations, were repurposed to work on the complicated
		problem of protein folding. In effect acting as a global
		supercomputer to aid medical research. Given the uniqueness of our
		GPU it might find a similar novel use in the future.
